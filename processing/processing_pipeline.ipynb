{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64af477f",
   "metadata": {},
   "source": [
    "# Geospatial Data Processing Pipeline\n",
    "\n",
    "This notebook demonstrates a complete pipeline for processing geospatial data from multiple sources into PMTiles format using:\n",
    "\n",
    "## Key Features\n",
    "- **Overture Maps download** via DuckDB with bounding box filtering\n",
    "- **Multi-format conversion** (Shapefile, GeoPackage, etc.) to GeoJSON\n",
    "- **Automated PMTiles generation** with optimized tippecanoe settings\n",
    "- **Modular architecture** for easy customization and debugging\n",
    "- **Progress tracking** with detailed logging and error handling\n",
    "- **Geometry-aware processing** with appropriate settings for each data type\n",
    "\n",
    "## Processing Steps\n",
    "1. **Download** - Fetch Overture Maps data for specified extent\n",
    "2. **Convert** - Transform custom spatial data to GeoJSON format\n",
    "3. **Tile** - Generate PMTiles using tippecanoe with optimized settings\n",
    "\n",
    "## Prerequisites\n",
    "- Python with required packages (duckdb, tqdm, pathlib)\n",
    "- Tippecanoe installed and available in PATH\n",
    "- GDAL/OGR for geospatial format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e8a8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully imported all processing modules\n"
     ]
    }
   ],
   "source": [
    "# Import the three modular processing scripts\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Add the processing directory to Python path\n",
    "processing_dir = Path(\"./processing\")\n",
    "if str(processing_dir) not in sys.path:\n",
    "    sys.path.append(str(processing_dir))\n",
    "\n",
    "# Import our modular processing scripts\n",
    "try:\n",
    "    from downloadOverture import download_overture_data\n",
    "    from convertCustomData import convert_file, convert_to_geojsonseq\n",
    "    from runCreateTiles import process_to_tiles, create_tilejson\n",
    "    print(\"✓ Successfully imported all processing modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules: {e}\")\n",
    "    print(\"Make sure the processing scripts are in the ./processing directory\")\n",
    "\n",
    "# Import additional libraries for visualization and analysis\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008eff0",
   "metadata": {},
   "source": [
    "## 1. Project Configuration and Paths\n",
    "\n",
    "Configure the project directories and processing parameters for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09545d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT CONFIGURATION INITIALIZED\n",
      "==================================================\n",
      "Project root: /Users/matthewheaton/GitHub/basemap\n",
      "Processing directory: /Users/matthewheaton/GitHub/basemap/processing\n",
      "Data directory: /Users/matthewheaton/GitHub/basemap/processing/data\n",
      "Overture data directory: /Users/matthewheaton/GitHub/basemap/overture/data\n",
      "Custom data directory: /Users/matthewheaton/GitHub/basemap/processing/input/grid3\n",
      "Tile output directory: /Users/matthewheaton/GitHub/basemap/processing/tiles\n",
      "Public tiles directory: /Users/matthewheaton/GitHub/basemap/public/tiles\n",
      "\n",
      "Processing extent: (22.0, -6.0, 24.0, -4.0)\n",
      "Buffer degrees: 0.2\n",
      "Area: 4.00 degree²\n",
      "\n",
      "All directories created and configuration loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "# Configuration - All paths and parameters centralized\n",
    "from pathlib import Path\n",
    "\n",
    "# Define all project paths\n",
    "PROJECT_ROOT = Path(__file__).resolve().parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "PROCESSING_DIR = PROJECT_ROOT / \"processing\"\n",
    "DATA_DIR = PROCESSING_DIR / \"data\"\n",
    "OVERTURE_DATA_DIR = PROJECT_ROOT / \"overture\" / \"data\"\n",
    "CUSTOM_DATA_DIR = PROCESSING_DIR / \"input\" / \"grid3\"\n",
    "TILE_DIR = PROCESSING_DIR / \"tiles\"\n",
    "PUBLIC_TILES_DIR = PROJECT_ROOT / \"public\" / \"tiles\"\n",
    "\n",
    "CONFIG = {\n",
    "    \"paths\": {\n",
    "        \"project_root\": PROJECT_ROOT,\n",
    "        \"processing_dir\": PROCESSING_DIR,\n",
    "        \"data_dir\": DATA_DIR,\n",
    "        \"overture_data_dir\": OVERTURE_DATA_DIR,\n",
    "        \"custom_data_dir\": CUSTOM_DATA_DIR,\n",
    "        \"tile_dir\": TILE_DIR,\n",
    "        \"public_tiles_dir\": PUBLIC_TILES_DIR,\n",
    "        \"template_path\": PROCESSING_DIR / \"tileQueries.template\"\n",
    "    },\n",
    "    \"extent\": {\n",
    "        \"coordinates\": (22.0, -6.0, 24.0, -4.0),  # kasai-oriental\n",
    "        \"buffer_degrees\": 0.2\n",
    "    },\n",
    "    \"download\": {\n",
    "        \"verbose\": True,\n",
    "        \"output_formats\": [\"*.geojson\", \"*.geojsonseq\"]\n",
    "    },\n",
    "    \"conversion\": {\n",
    "        \"input_patterns\": [\"*.shp\", \"*.gpkg\", \"*.gdb\", \"*.sqlite\", \"*.db\", \"*.geojson\", \"*.json\"],\n",
    "        \"output_suffix\": \".geojsonseq\",\n",
    "        \"reproject_crs\": \"EPSG:4326\",\n",
    "        \"overwrite\": True,\n",
    "        \"verbose\": True\n",
    "    },\n",
    "    \"tiling\": {\n",
    "        \"input_dirs\": [DATA_DIR, OVERTURE_DATA_DIR],  # Search in both data directories\n",
    "        \"output_dir\": TILE_DIR,\n",
    "        \"parallel\": True,\n",
    "        \"overwrite\": True,\n",
    "        \"verbose\": True,\n",
    "        \"create_tilejson\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create necessary directories\n",
    "for path_key, path_value in CONFIG[\"paths\"].items():\n",
    "    if path_key.endswith(\"_dir\") and path_value:\n",
    "        path_value.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"PROJECT CONFIGURATION INITIALIZED\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Project root: {CONFIG['paths']['project_root']}\")\n",
    "print(f\"Processing directory: {CONFIG['paths']['processing_dir']}\")\n",
    "print(f\"Data directory: {CONFIG['paths']['data_dir']}\")\n",
    "print(f\"Overture data directory: {CONFIG['paths']['overture_data_dir']}\")\n",
    "print(f\"Custom data directory: {CONFIG['paths']['custom_data_dir']}\")\n",
    "print(f\"Tile output directory: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"Public tiles directory: {CONFIG['paths']['public_tiles_dir']}\")\n",
    "print()\n",
    "print(f\"Processing extent: {CONFIG['extent']['coordinates']}\")\n",
    "print(f\"Buffer degrees: {CONFIG['extent']['buffer_degrees']}\")\n",
    "print(f\"Area: {(CONFIG['extent']['coordinates'][2] - CONFIG['extent']['coordinates'][0]) * (CONFIG['extent']['coordinates'][3] - CONFIG['extent']['coordinates'][1]):.2f} degree²\")\n",
    "print()\n",
    "print(\"All directories created and configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea97440",
   "metadata": {},
   "source": [
    "## 2. Download Overture Data with DuckDB\n",
    "\n",
    "Use the `downloadOverture.py` module to fetch geospatial data from Overture Maps. This module uses DuckDB to efficiently query and download data for specific geographic extents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b170545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 1: DOWNLOADING OVERTURE DATA ===\n",
      "=== DOWNLOADING SOURCE DATA ===\n",
      "Raw extent: (22.0, -6.0, 24.0, -4.0)\n",
      "Snapped extent: (21.09375, -7.0136679275666305, 25.3125, -2.8113711933311296)\n",
      "Map extent: 21.09375, -7.0136679275666305 to 25.3125, -2.8113711933311296\n",
      "Download extent (buffered): 20.89375, -7.213667927566631 to 25.5125, -2.6113711933311294\n",
      "Buffer: 0.2 degrees (~22.2km)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:   0%|          | 0/10 [00:00<?, ?section/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 1: base/land\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=base/type=land/*\n",
      "  -> Output: land.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  10%|█         | 1/10 [00:27<04:03, 27.09s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 2: base/land_use\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=base/type=land_use/*\n",
      "  -> Output: land_use.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  20%|██        | 2/10 [00:45<02:57, 22.20s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 3: base/land_use\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=base/type=land_use/*\n",
      "  -> Output: land_residential.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  30%|███       | 3/10 [00:48<01:33, 13.37s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 4: base/water\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=base/type=water/*\n",
      "  -> Output: water.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  40%|████      | 4/10 [01:19<02:01, 20.29s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 5: transportation/segment\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=transportation/type=segment/*\n",
      "  -> Output: roads.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  50%|█████     | 5/10 [02:30<03:12, 38.56s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 6: buildings/building\n",
      "  -> Querying: az://overturemapswestus2.blob.core.windows.net/release/2025-06-25.0/theme=buildings/type=building/*\n",
      "  -> Output: buildings.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  60%|██████    | 6/10 [07:01<07:49, 117.42s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 7: admins/locality\n",
      "  -> Querying: az://overturemapswestus2.blob.core.windows.net/release/2024-04-16-beta.0/theme=admins/type=locality/*\n",
      "  -> Output: placenames.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  70%|███████   | 7/10 [07:06<04:02, 80.89s/section] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 8: unknown\n",
      "  -> Querying: s3://overturemaps-us-west-2/release/2025-06-25.0/theme=places/*/*\n",
      "  -> Output: places.geojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  80%|████████  | 8/10 [07:16<01:56, 58.19s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 9: base/land_cover\n",
      "  -> Querying: az://overturemapswestus2.blob.core.windows.net/release/2025-06-25.0/theme=base/type=land_cover/*\n",
      "  -> Output: land_cover.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress:  90%|█████████ | 9/10 [09:08<01:15, 75.11s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing Section 10: base/infrastructure\n",
      "  -> Querying: az://overturemapswestus2.blob.core.windows.net/release/2025-06-25.0/theme=base/type=infrastructure/*\n",
      "  -> Output: infrastructure.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall progress: 100%|██████████| 10/10 [09:18<00:00, 55.82s/section]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SOURCE DATA DOWNLOAD COMPLETE ===\n",
      "\n",
      "Download completed: True\n",
      "Sections processed: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Overture Maps data\n",
    "print(\"=== STEP 1: DOWNLOADING OVERTURE DATA ===\")\n",
    "download_results = download_overture_data(\n",
    "    extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "    buffer_degrees=CONFIG[\"extent\"][\"buffer_degrees\"],\n",
    "    template_path=str(CONFIG[\"paths\"][\"template_path\"]),\n",
    "    verbose=CONFIG[\"download\"][\"verbose\"]\n",
    ")\n",
    "\n",
    "print(f\"Download completed: {download_results['success']}\")\n",
    "print(f\"Sections processed: {download_results['processed_sections']}\")\n",
    "if download_results[\"errors\"]:\n",
    "    print(f\"Errors encountered: {len(download_results['errors'])}\")\n",
    "    for error in download_results[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860e57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking downloaded files...\n",
      "\n",
      "Found 10 downloaded files:\n",
      "  GRID3_COD_health_areas_v5_0.geojson (281.7 MB)\n",
      "  GRID3_COD_health_facilities_v5_0.geojson (19.4 MB)\n",
      "  GRID3_COD_health_zones_v5_0.geojson (77.2 MB)\n",
      "  GRID3_COD_settlement_extents_v3_1.geojsonseq (2401.8 MB)\n",
      "  GRID3_COD_settlement_names_v5_0.geojson (50.4 MB)\n",
      "  infrastructure.geojsonseq (0.7 MB)\n",
      "  land.geojsonseq (7.1 MB)\n",
      "  land_cover.geojsonseq (356.1 MB)\n",
      "  land_residential.geojsonseq (7.7 MB)\n",
      "  land_use.geojsonseq (1.6 MB)\n",
      "\n",
      "Total size: 3203.5 MB\n"
     ]
    }
   ],
   "source": [
    "# Check what files were created during download\n",
    "print(\"=== CHECKING DOWNLOADED FILES ===\")\n",
    "\n",
    "overture_files = []\n",
    "search_dirs = [CONFIG[\"paths\"][\"data_dir\"], CONFIG[\"paths\"][\"overture_data_dir\"]]\n",
    "\n",
    "for data_dir in search_dirs:\n",
    "    if data_dir.exists():\n",
    "        for pattern in CONFIG[\"download\"][\"output_formats\"]:\n",
    "            files = list(data_dir.glob(pattern))\n",
    "            overture_files.extend(files)\n",
    "\n",
    "print(f\"Found {len(overture_files)} downloaded files:\")\n",
    "for file in sorted(overture_files):\n",
    "    file_size = file.stat().st_size / 1024 / 1024  # Size in MB\n",
    "    print(f\"  {file.name} ({file_size:.1f} MB)\")\n",
    "\n",
    "# Display file statistics\n",
    "if overture_files:\n",
    "    total_size_mb = sum(f.stat().st_size for f in overture_files) / 1024 / 1024\n",
    "    print(f\"\\nTotal size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"Search directories: {[str(d) for d in search_dirs]}\")\n",
    "else:\n",
    "    print(\"No files found. Check download results above.\")\n",
    "    print(f\"Searched in: {[str(d) for d in search_dirs]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bacbe99",
   "metadata": {},
   "source": [
    "## 3. Convert Custom Spatial Data for Tippecanoe\n",
    "\n",
    "Use the `convertCustomData.py` module to convert various geospatial formats to newline-delimited GeoJSON files suitable for Tippecanoe processing.\n",
    "\n",
    "### Supported Input Formats\n",
    "- Shapefile (.shp)\n",
    "- GeoPackage (.gpkg)\n",
    "- FileGDB (.gdb)\n",
    "- SQLite/SpatiaLite (.sqlite, .db)\n",
    "- PostGIS (connection string)\n",
    "- CSV with geometry columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21f4d5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 3: CONVERTING CUSTOM SPATIAL DATA ===\n",
      "Found 5 custom data files to convert:\n",
      "Search directory: /Users/matthewheaton/GitHub/basemap/processing/input/grid3\n",
      "  GRID3_COD_Settlement_Extents_v3_1.gpkg\n",
      "  GRID3_COD_health_zones_v5_0.geojson\n",
      "  GRID3_COD_health_facilities_v5_0.geojson\n",
      "  GRID3_COD_health_areas_v5_0.geojson\n",
      "  GRID3_COD_settlement_names_v5_0.geojson\n",
      "Converting GRID3_COD_Settlement_Extents_v3_1.gpkg...\n",
      "Processing 572537 features\n",
      "Processing 572537 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  18%|█▊        | 104693/572537 [02:00<08:58, 868.04features/s] \n",
      "Converting:   1%|          | 4628/572537 [00:01<04:05, 2314.63features/s]\n",
      "Converting:   2%|▏         | 10637/572537 [00:03<02:39, 3513.08features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 10000 features, 2850.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   3%|▎         | 18479/572537 [00:06<02:34, 3588.94features/s]\n",
      "\u001b[A\n",
      "Converting:   4%|▎         | 20336/572537 [00:06<03:23, 2712.11features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 20000 features, 3128.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   5%|▌         | 30571/572537 [00:10<02:37, 3437.85features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 30000 features, 2739.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   7%|▋         | 40124/572537 [00:13<02:18, 3840.74features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 40000 features, 3263.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:   9%|▉         | 50697/572537 [00:16<02:20, 3724.47features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 50000 features, 3074.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  11%|█         | 60649/572537 [00:20<04:20, 1968.03features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 60000 features, 2671.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  12%|█▏        | 70373/572537 [00:23<02:09, 3874.66features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 70000 features, 3708.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  14%|█▍        | 80489/572537 [00:26<02:26, 3358.92features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 80000 features, 3567.3 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  16%|█▌        | 90687/572537 [00:29<02:12, 3624.43features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 90000 features, 3387.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  18%|█▊        | 100364/572537 [00:31<02:06, 3734.14features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 100000 features, 3466.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  19%|█▉        | 110477/572537 [00:34<02:07, 3620.83features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 110000 features, 3712.3 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  21%|██        | 120466/572537 [00:37<02:13, 3375.99features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 120000 features, 3441.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  23%|██▎       | 130384/572537 [00:40<02:17, 3214.19features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 130000 features, 3304.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  24%|██▍       | 140182/572537 [00:43<02:18, 3111.64features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 140000 features, 3411.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  26%|██▋       | 150713/572537 [00:46<01:50, 3805.72features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 150000 features, 3674.3 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  28%|██▊       | 160770/572537 [00:49<02:00, 3413.72features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 160000 features, 3269.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  30%|██▉       | 170462/572537 [00:52<01:53, 3531.70features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 170000 features, 3493.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  32%|███▏      | 180485/572537 [00:55<02:02, 3202.78features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 180000 features, 3402.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  33%|███▎      | 190539/572537 [00:57<01:42, 3722.59features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 190000 features, 3482.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  35%|███▍      | 200328/572537 [01:00<01:46, 3507.67features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 200000 features, 3618.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  37%|███▋      | 210524/572537 [01:03<01:53, 3201.31features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 210000 features, 3488.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  38%|███▊      | 220382/572537 [01:06<01:58, 2973.87features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 220000 features, 3221.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  40%|████      | 230614/572537 [01:09<02:10, 2612.46features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 230000 features, 3252.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  42%|████▏     | 240497/572537 [01:12<01:31, 3632.59features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 240000 features, 3647.4 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  44%|████▍     | 250703/572537 [01:15<01:42, 3148.14features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 250000 features, 3422.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  46%|████▌     | 260572/572537 [01:18<01:26, 3626.53features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 260000 features, 3662.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  47%|████▋     | 270556/572537 [01:21<01:13, 4133.54features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 270000 features, 3274.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  49%|████▉     | 280407/572537 [01:24<01:43, 2818.56features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 280000 features, 2920.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  51%|█████     | 290361/572537 [01:27<01:27, 3229.10features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 290000 features, 3045.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  52%|█████▏    | 300489/572537 [01:31<01:15, 3580.28features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 300000 features, 2971.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  54%|█████▍    | 310464/572537 [01:34<01:11, 3685.41features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 310000 features, 3204.4 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  56%|█████▌    | 320395/572537 [01:37<01:12, 3500.11features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 320000 features, 2875.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  58%|█████▊    | 330174/572537 [01:40<01:34, 2553.44features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 330000 features, 3402.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  59%|█████▉    | 340540/572537 [01:44<01:10, 3295.31features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 340000 features, 2879.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  61%|██████    | 350470/572537 [01:47<01:05, 3400.93features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 350000 features, 3385.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  63%|██████▎   | 360505/572537 [01:50<01:01, 3438.13features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 360000 features, 3214.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  65%|██████▍   | 370657/572537 [01:52<00:52, 3822.84features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 370000 features, 3845.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  66%|██████▋   | 380366/572537 [01:55<00:55, 3489.97features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 380000 features, 3265.6 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  68%|██████▊   | 390372/572537 [01:58<00:46, 3875.87features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 390000 features, 3879.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  70%|██████▉   | 400706/572537 [02:01<00:44, 3903.08features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 400000 features, 3849.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  72%|███████▏  | 410538/572537 [02:03<00:50, 3194.63features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 410000 features, 3614.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  73%|███████▎  | 420494/572537 [02:06<00:39, 3825.83features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 420000 features, 3514.9 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  75%|███████▌  | 430466/572537 [02:10<00:50, 2840.25features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 430000 features, 2769.8 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  77%|███████▋  | 440421/572537 [02:13<00:33, 3905.69features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 440000 features, 2973.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  79%|███████▊  | 450268/572537 [02:16<00:35, 3430.63features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 450000 features, 3290.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  80%|████████  | 460161/572537 [02:20<00:36, 3069.27features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 460000 features, 3013.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  82%|████████▏ | 470755/572537 [02:23<00:29, 3397.86features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 470000 features, 2791.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  84%|████████▍ | 480433/572537 [02:26<00:26, 3455.06features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 480000 features, 3409.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  86%|████████▌ | 490336/572537 [02:29<00:29, 2784.02features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 490000 features, 3212.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  87%|████████▋ | 500543/572537 [02:32<00:19, 3688.86features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 500000 features, 3308.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  89%|████████▉ | 510531/572537 [02:35<00:15, 3922.47features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 510000 features, 3466.1 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  91%|█████████ | 520386/572537 [02:38<00:15, 3463.36features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 520000 features, 3344.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  93%|█████████▎| 530709/572537 [02:41<00:11, 3597.47features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 530000 features, 3663.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  94%|█████████▍| 540392/572537 [02:44<00:09, 3543.39features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 540000 features, 3351.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  96%|█████████▌| 550571/572537 [02:47<00:06, 3635.11features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 550000 features, 3657.5 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  98%|█████████▊| 560552/572537 [02:49<00:03, 3666.65features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 560000 features, 3592.2 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|█████████▉| 570365/572537 [02:53<00:01, 2131.33features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 570000 features, 2926.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 572537/572537 [02:54<00:00, 3283.66features/s]\n",
      "Converting: 100%|██████████| 572537/572537 [02:54<00:00, 3283.66features/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: 572537 features processed, 0 features skipped\n",
      "Output written to: /Users/matthewheaton/GitHub/basemap/processing/data/GRID3_COD_Settlement_Extents_v3_1.geojsonseq\n",
      "✓ Converted: 572537 features, 0 skipped\n",
      "  Output: GRID3_COD_Settlement_Extents_v3_1.geojsonseq\n",
      "Converting GRID3_COD_health_zones_v5_0.geojson...\n",
      "Processing 329 features\n",
      "Processing 329 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 329/329 [00:06<00:00, 49.22features/s] \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: 329 features processed, 0 features skipped\n",
      "Output written to: /Users/matthewheaton/GitHub/basemap/processing/data/GRID3_COD_health_zones_v5_0.geojsonseq\n",
      "✓ Converted: 329 features, 0 skipped\n",
      "  Output: GRID3_COD_health_zones_v5_0.geojsonseq\n",
      "Converting GRID3_COD_health_facilities_v5_0.geojson...\n",
      "Processing 27213 features\n",
      "Processing 27213 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  41%|████      | 11193/27213 [00:01<00:01, 11596.26features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 10000 features, 11129.7 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting:  79%|███████▊  | 21415/27213 [00:01<00:00, 10400.10features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed: 20000 features, 10860.0 features/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 27213/27213 [00:02<00:00, 11001.42features/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion complete: 27213 features processed, 0 features skipped\n",
      "Output written to: /Users/matthewheaton/GitHub/basemap/processing/data/GRID3_COD_health_facilities_v5_0.geojsonseq\n",
      "✓ Converted: 27213 features, 0 skipped\n",
      "  Output: GRID3_COD_health_facilities_v5_0.geojsonseq\n",
      "\n",
      "✓ Successfully converted 3 files\n",
      "  Output directory: /Users/matthewheaton/GitHub/basemap/processing/data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Look for custom data files to convert\n",
    "print(\"=== STEP 3: CONVERTING CUSTOM SPATIAL DATA ===\")\n",
    "\n",
    "custom_input_dir = CONFIG[\"paths\"][\"custom_data_dir\"]\n",
    "custom_files = []\n",
    "\n",
    "# Search for various spatial data formats using CONFIG patterns\n",
    "for pattern in CONFIG[\"conversion\"][\"input_patterns\"]:\n",
    "    custom_files.extend(custom_input_dir.glob(pattern))\n",
    "\n",
    "print(f\"Found {len(custom_files)} custom data files to convert:\")\n",
    "print(f\"Search directory: {custom_input_dir}\")\n",
    "for file in custom_files:\n",
    "    print(f\"  {file.name}\")\n",
    "\n",
    "# Convert custom data files (if any exist)\n",
    "converted_files = []\n",
    "\n",
    "for input_file in custom_files[:3]:  # Convert first 3 files as example\n",
    "    output_file = CONFIG[\"paths\"][\"data_dir\"] / f\"{input_file.stem}{CONFIG['conversion']['output_suffix']}\"\n",
    "    \n",
    "    print(f\"Converting {input_file.name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Convert using the modular function with CONFIG settings\n",
    "        processed, skipped, output_path = convert_file(\n",
    "            input_path=str(input_file),\n",
    "            output_path=str(output_file),\n",
    "            reproject=CONFIG[\"conversion\"][\"reproject_crs\"],\n",
    "            verbose=CONFIG[\"conversion\"][\"verbose\"]\n",
    "        )\n",
    "        \n",
    "        converted_files.append(output_file)\n",
    "        print(f\"✓ Converted: {processed} features, {skipped} skipped\")\n",
    "        print(f\"  Output: {output_file.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error converting {input_file.name}: {e}\")\n",
    "\n",
    "if converted_files:\n",
    "    print(f\"\\n✓ Successfully converted {len(converted_files)} files\")\n",
    "    print(f\"  Output directory: {CONFIG['paths']['data_dir']}\")\n",
    "else:\n",
    "    print(f\"\\nNo custom files to convert. Add data files to: {custom_input_dir}\")\n",
    "    print(f\"Supported formats: {', '.join(CONFIG['conversion']['input_patterns'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60968d93",
   "metadata": {},
   "source": [
    "## 4. Process GeoJSON/GeoJSONSeq to PMTiles\n",
    "\n",
    "Use the `runCreateTiles.py` module to convert GeoJSON and GeoJSONSeq files to PMTiles using optimized Tippecanoe settings.\n",
    "\n",
    "### Automatic Optimization Features\n",
    "- **Geometry Detection**: Automatically detects Point, LineString, or Polygon geometries\n",
    "- **Layer-Specific Settings**: Optimized settings for water, roads, places, land use, etc.\n",
    "- **Parallel Processing**: Multi-threaded processing for large datasets\n",
    "- **Quality Optimization**: Smart simplification and feature dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a575ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 4: PROCESSING TO PMTILES ===\n",
      "=== PROCESSING TO TILES ===\n",
      "Found 15 files to process:\n",
      "  GRID3_COD_health_zones_v5_0.geojsonseq\n",
      "  land_use.geojsonseq\n",
      "  land_residential.geojsonseq\n",
      "  land_cover.geojsonseq\n",
      "  GRID3_COD_Settlement_Extents_v3_1.geojsonseq\n",
      "  land.geojsonseq\n",
      "  GRID3_COD_health_facilities_v5_0.geojsonseq\n",
      "  infrastructure.geojsonseq\n",
      "  placenames.geojson\n",
      "  places.geojson\n",
      "  land_use.geojsonseq\n",
      "  water.geojsonseq\n",
      "  land.geojsonseq\n",
      "  buildings.geojsonseq\n",
      "  roads.geojsonseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:   0%|          | 0/15 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected geometry type: Mixed for GRID3_COD_health_zones_v5_0.geojsonseq (0.189s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      "\n",
      "Processing files:   0%|          | 0/15 [00:02<?, ?file/s]                 \n",
      "Processing files:   7%|▋         | 1/15 [00:02<00:37,  2.70s/file]\n",
      "\n",
      "Processing files:   0%|          | 0/15 [00:02<?, ?file/s]                 \n",
      "Processing files:   7%|▋         | 1/15 [00:02<00:37,  2.70s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land_use.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/land_use.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:   7%|▋         | 1/15 [00:03<00:37,  2.70s/file]         \n",
      "Processing files:  13%|█▎        | 2/15 [00:03<00:23,  1.81s/file]\n",
      "\n",
      "Processing files:   7%|▋         | 1/15 [00:03<00:37,  2.70s/file]         \n",
      "Processing files:  13%|█▎        | 2/15 [00:03<00:23,  1.81s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land_residential.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/land_residential.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:  13%|█▎        | 2/15 [00:11<00:23,  1.81s/file]         \n",
      "Processing files:  20%|██        | 3/15 [00:11<00:52,  4.34s/file]\n",
      "\n",
      "Processing files:  13%|█▎        | 2/15 [00:11<00:23,  1.81s/file]         \n",
      "Processing files:  20%|██        | 3/15 [00:11<00:52,  4.34s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRID3_COD_health_zones_v5_0.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/GRID3_COD_health_zones_v5_0.pmtiles\n",
      "  Detected geometry type: Point for GRID3_COD_health_facilities_v5_0.geojsonseq (0.022s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:  20%|██        | 3/15 [00:14<00:52,  4.34s/file]         \n",
      "Processing files:  27%|██▋       | 4/15 [00:14<00:42,  3.90s/file]\n",
      "\n",
      "Processing files:  20%|██        | 3/15 [00:14<00:52,  4.34s/file]         \n",
      "Processing files:  27%|██▋       | 4/15 [00:14<00:42,  3.90s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/land.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:  27%|██▋       | 4/15 [00:18<00:42,  3.90s/file]         \n",
      "Processing files:  33%|███▎      | 5/15 [00:18<00:38,  3.82s/file]\n",
      "\n",
      "Processing files:  27%|██▋       | 4/15 [00:18<00:42,  3.90s/file]         \n",
      "Processing files:  33%|███▎      | 5/15 [00:18<00:38,  3.82s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRID3_COD_health_facilities_v5_0.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/GRID3_COD_health_facilities_v5_0.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:  33%|███▎      | 5/15 [00:19<00:38,  3.82s/file]         \n",
      "Processing files:  40%|████      | 6/15 [00:19<00:26,  2.96s/file]\n",
      "\n",
      "Processing files:  33%|███▎      | 5/15 [00:19<00:38,  3.82s/file]         \n",
      "Processing files:  40%|████      | 6/15 [00:19<00:26,  2.96s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ infrastructure.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/infrastructure.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:  40%|████      | 6/15 [00:22<00:26,  2.96s/file]         \n",
      "Processing files:  47%|████▋     | 7/15 [00:22<00:22,  2.87s/file]\n",
      "\n",
      "Processing files:  40%|████      | 6/15 [00:22<00:26,  2.96s/file]         \n",
      "Processing files:  47%|████▋     | 7/15 [00:22<00:22,  2.87s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ placenames.geojson -> /Users/matthewheaton/GitHub/basemap/processing/tiles/placenames.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:  47%|████▋     | 7/15 [00:23<00:22,  2.87s/file]         \n",
      "Processing files:  53%|█████▎    | 8/15 [00:23<00:16,  2.37s/file]\n",
      "\n",
      "Processing files:  47%|████▋     | 7/15 [00:23<00:22,  2.87s/file]         \n",
      "Processing files:  53%|█████▎    | 8/15 [00:23<00:16,  2.37s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ places.geojson -> /Users/matthewheaton/GitHub/basemap/processing/tiles/places.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:  53%|█████▎    | 8/15 [00:25<00:16,  2.37s/file]         \n",
      "Processing files:  60%|██████    | 9/15 [00:25<00:13,  2.28s/file]\n",
      "\n",
      "Processing files:  53%|█████▎    | 8/15 [00:25<00:16,  2.37s/file]         \n",
      "Processing files:  60%|██████    | 9/15 [00:25<00:13,  2.28s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land_cover.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/land_cover.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \n",
      "\n",
      "Processing files:  60%|██████    | 9/15 [00:25<00:13,  2.28s/file]         \n",
      "Processing files:  67%|██████▋   | 10/15 [00:25<00:08,  1.64s/file]\n",
      "\n",
      "Processing files:  60%|██████    | 9/15 [00:25<00:13,  2.28s/file]         \n",
      "Processing files:  67%|██████▋   | 10/15 [00:25<00:08,  1.64s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land_use.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/land_use.pmtiles\n",
      "  Detected geometry type: Polygon for buildings.geojsonseq (0.890s)\n",
      "  Detected geometry type: Polygon for buildings.geojsonseq (0.890s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \n",
      "\n",
      "Processing files:  67%|██████▋   | 10/15 [00:27<00:08,  1.64s/file]        \n",
      "Processing files:  73%|███████▎  | 11/15 [00:27<00:06,  1.67s/file]\n",
      "\n",
      "Processing files:  67%|██████▋   | 10/15 [00:27<00:08,  1.64s/file]        \n",
      "Processing files:  73%|███████▎  | 11/15 [00:27<00:06,  1.67s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ water.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/water.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \n",
      "\n",
      "Processing files:  73%|███████▎  | 11/15 [00:33<00:06,  1.67s/file]        \n",
      "Processing files:  80%|████████  | 12/15 [00:33<00:08,  2.92s/file]\n",
      "\n",
      "Processing files:  73%|███████▎  | 11/15 [00:33<00:06,  1.67s/file]        \n",
      "Processing files:  80%|████████  | 12/15 [00:33<00:08,  2.92s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRID3_COD_Settlement_Extents_v3_1.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/GRID3_COD_Settlement_Extents_v3_1.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \n",
      "\n",
      "Processing files:  80%|████████  | 12/15 [00:33<00:08,  2.92s/file]        \n",
      "Processing files:  87%|████████▋ | 13/15 [00:33<00:04,  2.22s/file]\n",
      "\n",
      "Processing files:  80%|████████  | 12/15 [00:33<00:08,  2.92s/file]        \n",
      "Processing files:  87%|████████▋ | 13/15 [00:33<00:04,  2.22s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ land.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/land.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \n",
      "\n",
      "Processing files:  87%|████████▋ | 13/15 [00:34<00:04,  2.22s/file]        \n",
      "Processing files:  93%|█████████▎| 14/15 [00:34<00:01,  1.88s/file]\n",
      "\n",
      "Processing files:  87%|████████▋ | 13/15 [00:34<00:04,  2.22s/file]        \n",
      "Processing files:  93%|█████████▎| 14/15 [00:34<00:01,  1.88s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ roads.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/roads.pmtiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \n",
      "\n",
      "Processing files:  93%|█████████▎| 14/15 [01:01<00:01,  1.88s/file]        \n",
      "Processing files: 100%|██████████| 15/15 [01:01<00:00,  4.09s/file]\n",
      "\n",
      "Processing files:  93%|█████████▎| 14/15 [01:01<00:01,  1.88s/file]        \n",
      "Processing files: 100%|██████████| 15/15 [01:01<00:00,  4.09s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ buildings.geojsonseq -> /Users/matthewheaton/GitHub/basemap/processing/tiles/buildings.pmtiles\n",
      "\n",
      "=== TILE PROCESSING COMPLETE ===\n",
      "Processed: 15/15 files\n",
      "Tiling completed: True\n",
      "Files processed: 15/15\n",
      "\n",
      "✓ Successfully generated 15 PMTiles:\n",
      "  GRID3_COD_Settlement_Extents_v3_1.pmtiles (3.4 MB)\n",
      "  GRID3_COD_health_facilities_v5_0.pmtiles (1.9 MB)\n",
      "  GRID3_COD_health_zones_v5_0.pmtiles (2.5 MB)\n",
      "  buildings.pmtiles (13.3 MB)\n",
      "  infrastructure.pmtiles (0.1 MB)\n",
      "  land.pmtiles (0.3 MB)\n",
      "  land_cover.pmtiles (29.4 MB)\n",
      "  land_residential.pmtiles (1.3 MB)\n",
      "  land_use.pmtiles (1.3 MB)\n",
      "  placenames.pmtiles (0.3 MB)\n",
      "  places.pmtiles (0.2 MB)\n",
      "  roads.pmtiles (6.5 MB)\n",
      "  water.pmtiles (2.0 MB)\n",
      "\n",
      "Total PMTiles size: 62.5 MB\n",
      "Files location: /Users/matthewheaton/GitHub/basemap/processing/tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Process all GeoJSON/GeoJSONSeq files to PMTiles\n",
    "print(\"=== STEP 4: PROCESSING TO PMTILES ===\")\n",
    "\n",
    "# Process all downloaded and converted files to PMTiles using CONFIG settings\n",
    "tiling_results = process_to_tiles(\n",
    "    extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "    input_dirs=[str(d) for d in CONFIG[\"tiling\"][\"input_dirs\"]],  # Convert Path objects to strings\n",
    "    output_dir=str(CONFIG[\"paths\"][\"tile_dir\"]), \n",
    "    parallel=CONFIG[\"tiling\"][\"parallel\"],\n",
    "    verbose=CONFIG[\"tiling\"][\"verbose\"]\n",
    ")\n",
    "\n",
    "print(f\"Tiling completed: {tiling_results['success']}\")\n",
    "print(f\"Files processed: {len(tiling_results['processed_files'])}/{tiling_results['total_files']}\")\n",
    "\n",
    "if tiling_results[\"errors\"]:\n",
    "    print(f\"Errors encountered: {len(tiling_results['errors'])}\")\n",
    "    for error in tiling_results[\"errors\"]:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "# Display generated PMTiles files\n",
    "if tiling_results[\"processed_files\"]:\n",
    "    print(f\"\\n✓ Successfully generated {len(tiling_results['processed_files'])} PMTiles:\")\n",
    "    \n",
    "    pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "    \n",
    "    total_size_mb = 0\n",
    "    for pmtile in sorted(pmtiles_files):\n",
    "        size_mb = pmtile.stat().st_size / 1024 / 1024\n",
    "        total_size_mb += size_mb\n",
    "        print(f\"  {pmtile.name} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    print(f\"\\nTotal PMTiles size: {total_size_mb:.1f} MB\")\n",
    "    print(f\"Files location: {CONFIG['paths']['tile_dir']}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo PMTiles files were generated. Check the errors above.\")\n",
    "    print(f\"Make sure you have GeoJSON/GeoJSONSeq files in: {[str(d) for d in CONFIG['tiling']['input_dirs']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f46e1",
   "metadata": {},
   "source": [
    "## 5. Create TileJSON Metadata\n",
    "\n",
    "Generate TileJSON metadata files for seamless integration with web mapping libraries like MapLibre GL JS.\n",
    "\n",
    "### TileJSON Features\n",
    "- **Bounds and zoom levels** automatically detected from PMTiles\n",
    "- **Vector layer definitions** for each data layer\n",
    "- **MapLibre GL JS compatibility** for easy web integration\n",
    "- **PMTiles URL references** for efficient tile serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57093621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STEP 5: CREATING TILEJSON METADATA ===\n",
      "Found 13 PMTiles files, creating TileJSON...\n",
      "TileJSON created: /Users/matthewheaton/GitHub/basemap/processing/tiles/tilejson.json\n",
      "Found 13 PMTiles files\n",
      "✓ TileJSON created successfully\n",
      "  Bounds: [22.0, -6.0, 24.0, -4.0]\n",
      "  Zoom range: 0 - 16\n",
      "  Vector layers: 13\n",
      "  Output file: /Users/matthewheaton/GitHub/basemap/processing/tiles/tilejson.json\n",
      "\n",
      "Complete output summary:\n",
      "  GRID3_COD_Settlement_Extents_v3_1.pmtiles (3.4 MB)\n",
      "  GRID3_COD_health_facilities_v5_0.pmtiles (1.9 MB)\n",
      "  GRID3_COD_health_zones_v5_0.pmtiles (2.5 MB)\n",
      "  buildings.pmtiles (13.3 MB)\n",
      "  infrastructure.pmtiles (0.1 MB)\n",
      "  land.pmtiles (0.3 MB)\n",
      "  land_cover.pmtiles (29.4 MB)\n",
      "  land_residential.pmtiles (1.3 MB)\n",
      "  land_use.pmtiles (1.3 MB)\n",
      "  placenames.pmtiles (0.3 MB)\n",
      "  places.pmtiles (0.2 MB)\n",
      "  roads.pmtiles (6.5 MB)\n",
      "  water.pmtiles (2.0 MB)\n",
      "  tilejson.json\n",
      "\n",
      "Total PMTiles size: 62.5 MB\n",
      "All files location: /Users/matthewheaton/GitHub/basemap/processing/tiles\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Create TileJSON metadata for MapLibre integration\n",
    "print(\"=== STEP 5: CREATING TILEJSON METADATA ===\")\n",
    "\n",
    "# Check if PMTiles files exist in the configured tile directory\n",
    "pmtiles_files = list(CONFIG[\"paths\"][\"tile_dir\"].glob(\"*.pmtiles\"))\n",
    "\n",
    "if pmtiles_files:\n",
    "    print(f\"Found {len(pmtiles_files)} PMTiles files, creating TileJSON...\")\n",
    "    \n",
    "    try:\n",
    "        tilejson = create_tilejson(\n",
    "            tile_dir=CONFIG[\"paths\"][\"tile_dir\"],\n",
    "            extent=CONFIG[\"extent\"][\"coordinates\"],\n",
    "            output_file=CONFIG[\"paths\"][\"tile_dir\"] / \"tilejson.json\"\n",
    "        )\n",
    "        \n",
    "        print(\"✓ TileJSON created successfully\")\n",
    "        print(f\"  Bounds: {tilejson['bounds']}\")\n",
    "        print(f\"  Zoom range: {tilejson['minzoom']} - {tilejson['maxzoom']}\")\n",
    "        print(f\"  Vector layers: {len(tilejson['vector_layers'])}\")\n",
    "        print(f\"  Output file: {CONFIG['paths']['tile_dir'] / 'tilejson.json'}\")\n",
    "        \n",
    "        # Show a summary of all output files\n",
    "        print(f\"\\nComplete output summary:\")\n",
    "        total_size_mb = 0\n",
    "        for pmtile in sorted(pmtiles_files):\n",
    "            size_mb = pmtile.stat().st_size / 1024 / 1024\n",
    "            total_size_mb += size_mb\n",
    "            print(f\"  {pmtile.name} ({size_mb:.1f} MB)\")\n",
    "        \n",
    "        print(f\"  tilejson.json\")\n",
    "        print(f\"\\nTotal PMTiles size: {total_size_mb:.1f} MB\")\n",
    "        print(f\"All files location: {CONFIG['paths']['tile_dir']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ TileJSON creation failed: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"No PMTiles files found in output directory.\")\n",
    "    print(f\"Expected location: {CONFIG['paths']['tile_dir']}\")\n",
    "    print(\"Run Step 4 first to generate PMTiles files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755057e5",
   "metadata": {},
   "source": [
    "## 6. Validate and Test Individual Steps\n",
    "\n",
    "Test each processing step individually and validate the generated outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 INDIVIDUAL STEP TESTING\n",
      "==================================================\n",
      "\n",
      "1. Test downloadOverture.py standalone:\n",
      "python processing/downloadOverture.py --extent='23.4,-6.2,23.8,-5.8' --buffer=0.1\n",
      "\n",
      "2. Test convertCustomData.py standalone:\n",
      "python processing/convertCustomData.py input.shp output.geojsonseq --reproject=EPSG:4326\n",
      "\n",
      "3. Test runCreateTiles.py standalone:\n",
      "python processing/runCreateTiles.py --extent='23.4,-6.2,23.8,-5.8' --create-tilejson\n",
      "\n",
      "4. Test individual steps in this notebook:\n",
      "   - Step 1: Download section (cell 6)\n",
      "   - Step 2: Check downloaded files (cell 7)\n",
      "   - Step 3: Convert custom data (cell 9)\n",
      "   - Step 4: Process to PMTiles (cell 11)\n",
      "   - Step 5: Create TileJSON (cell 13)\n",
      "\n",
      "5. Validate outputs:\n",
      "   - Check data/ directory for GeoJSON files\n",
      "   - Check tiles/ directory for PMTiles files\n",
      "   - Verify TileJSON metadata file\n",
      "\n",
      "📋 CURRENT CONFIGURATION VALIDATION\n",
      "==================================================\n",
      "Extent: (22.0, -6.0, 24.0, -4.0)\n",
      "Buffer: 0.2 degrees\n",
      "Output directory: tiles\n",
      "Custom data directory: ['input/grid3']\n",
      "Processing area: 4.00 degree² (49284 km²)\n",
      "\n",
      "🎯 PERFORMANCE OPTIMIZATION TIPS\n",
      "==================================================\n",
      "\n",
      "1. For large areas:\n",
      "   - Increase buffer for downloads: buffer_degrees=0.5\n",
      "   - Use parallel processing: parallel=True\n",
      "   - Process in smaller chunks if memory issues occur\n",
      "\n",
      "2. For small areas:\n",
      "   - Smaller buffer: buffer_degrees=0.1\n",
      "   - Sequential processing may be faster: parallel=False\n",
      "\n",
      "3. Memory optimization:\n",
      "   - Monitor data/ directory size during processing\n",
      "   - Clean intermediate files between steps if needed\n",
      "   - Use filter patterns to process specific layers only\n"
     ]
    }
   ],
   "source": [
    "# Individual Step Testing and Validation\n",
    "\n",
    "print(\"INDIVIDUAL STEP TESTING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. Test downloadOverture.py standalone:\")\n",
    "print(\"python processing/downloadOverture.py --extent='23.4,-6.2,23.8,-5.8' --buffer=0.1\")\n",
    "\n",
    "print(\"\\n2. Test convertCustomData.py standalone:\")\n",
    "print(\"python processing/convertCustomData.py input.shp output.geojsonseq --reproject=EPSG:4326\")\n",
    "\n",
    "print(\"\\n3. Test runCreateTiles.py standalone:\")\n",
    "print(\"python processing/runCreateTiles.py --extent='23.4,-6.2,23.8,-5.8' --create-tilejson\")\n",
    "\n",
    "print(\"\\n4. Test individual steps in this notebook:\")\n",
    "print(\"   - Step 1: Download section (cell 6)\")\n",
    "print(\"   - Step 2: Check downloaded files (cell 7)\")\n",
    "print(\"   - Step 3: Convert custom data (cell 9)\")\n",
    "print(\"   - Step 4: Process to PMTiles (cell 11)\")\n",
    "print(\"   - Step 5: Create TileJSON (cell 13)\")\n",
    "\n",
    "print(\"\\n5. Validate outputs using CONFIG paths:\")\n",
    "print(f\"   - Check {CONFIG['paths']['data_dir']} for GeoJSON files\")\n",
    "print(f\"   - Check {CONFIG['paths']['tile_dir']} for PMTiles files\")\n",
    "print(f\"   - Verify TileJSON metadata file\")\n",
    "\n",
    "# Configuration validation using centralized CONFIG\n",
    "print(\"\\nCURRENT CONFIGURATION VALIDATION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Extent: {CONFIG['extent']['coordinates']}\")\n",
    "print(f\"Buffer: {CONFIG['extent']['buffer_degrees']} degrees\")\n",
    "print(f\"Tile output directory: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"Custom data directory: {CONFIG['paths']['custom_data_dir']}\")\n",
    "print(f\"Input directories for tiling: {[str(d) for d in CONFIG['tiling']['input_dirs']]}\")\n",
    "\n",
    "# Area calculation using CONFIG\n",
    "extent = CONFIG['extent']['coordinates']\n",
    "area = (extent[2] - extent[0]) * (extent[3] - extent[1])\n",
    "print(f\"Processing area: {area:.2f} degree² ({area * 111**2:.0f} km²)\")\n",
    "\n",
    "# Check directory status\n",
    "print(f\"\\nDIRECTORY STATUS\")\n",
    "print(\"=\" * 30)\n",
    "for path_name, path_obj in CONFIG['paths'].items():\n",
    "    if path_name.endswith('_dir'):\n",
    "        status = \"exists\" if path_obj.exists() else \"missing\"\n",
    "        file_count = len(list(path_obj.glob(\"*\"))) if path_obj.exists() else 0\n",
    "        print(f\"{path_name}: {status} ({file_count} files)\")\n",
    "\n",
    "print(\"\\nPERFORMANCE OPTIMIZATION TIPS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\n1. For large areas (current: {area:.2f} degree²):\")\n",
    "print(f\"   - Current buffer: {CONFIG['extent']['buffer_degrees']} degrees\")\n",
    "print(f\"   - Parallel processing: {CONFIG['tiling']['parallel']}\")\n",
    "print(\"   - Consider smaller chunks if memory issues occur\")\n",
    "\n",
    "print(\"\\n2. File management:\")\n",
    "print(f\"   - Monitor {CONFIG['paths']['data_dir']} size during processing\")\n",
    "print(\"   - Clean intermediate files between steps if needed\")\n",
    "print(\"   - Use filter patterns to process specific layers only\")\n",
    "\n",
    "print(\"\\n3. Output optimization:\")\n",
    "print(f\"   - PMTiles output: {CONFIG['paths']['tile_dir']}\")\n",
    "print(f\"   - Public tiles: {CONFIG['paths']['public_tiles_dir']}\")\n",
    "print(\"   - Copy final tiles to public directory for web serving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ee77b",
   "metadata": {},
   "source": [
    "# Modular Processing Summary\n",
    "\n",
    "This notebook provides a complete, step-by-step approach for geospatial data processing with the following capabilities:\n",
    "\n",
    "## Core Steps\n",
    "1. **Download Overture Maps data** with spatial filtering using DuckDB\n",
    "2. **Check and validate** downloaded files \n",
    "3. **Convert custom spatial data** to GeoJSON format\n",
    "4. **Generate PMTiles** using optimized tippecanoe settings\n",
    "5. **Create TileJSON metadata** for web mapping integration\n",
    "6. **Validate and test** individual processing steps\n",
    "\n",
    "## Key Features\n",
    "- **Modular design** - Each step can be run independently\n",
    "- **Flexible configuration** - Easy to customize for different areas and data types\n",
    "- **Interactive development** - Run steps individually for debugging\n",
    "- **Performance optimized** - Appropriate settings for different geometry types\n",
    "- **Production ready** - Robust error handling and validation\n",
    "\n",
    "## Output Files\n",
    "Each step generates specific outputs that can be directly used:\n",
    "- **GeoJSON/GeoJSONSeq files** for further processing or analysis\n",
    "- **PMTiles files** for efficient web mapping\n",
    "- **TileJSON metadata** for MapLibre GL JS integration\n",
    "\n",
    "## Usage Patterns\n",
    "- **Development**: Run steps individually for testing and debugging\n",
    "- **Production**: Execute all steps in sequence for automated processing\n",
    "- **Customization**: Modify CONFIG settings and re-run specific steps\n",
    "- **Integration**: Use generated files with web mapping applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
